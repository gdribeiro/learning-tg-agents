{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in ./venv/lib/python3.9/site-packages (2.4.0)\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.9/site-packages (from imageio) (9.2.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from imageio) (1.23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyvirtualdisplay in ./venv/lib/python3.9/site-packages (3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tf-agents in ./venv/lib/python3.9/site-packages (0.13.0)\n",
      "Requirement already satisfied: absl-py>=0.6.1 in ./venv/lib/python3.9/site-packages (from tf-agents) (1.2.0)\n",
      "Requirement already satisfied: pygame==2.1.0 in ./venv/lib/python3.9/site-packages (from tf-agents) (2.1.0)\n",
      "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in ./venv/lib/python3.9/site-packages (from tf-agents) (0.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.9/site-packages (from tf-agents) (4.3.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in ./venv/lib/python3.9/site-packages (from tf-agents) (2.1.0)\n",
      "Requirement already satisfied: gin-config>=0.4.0 in ./venv/lib/python3.9/site-packages (from tf-agents) (0.5.0)\n",
      "Requirement already satisfied: six>=1.10.0 in ./venv/lib/python3.9/site-packages (from tf-agents) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./venv/lib/python3.9/site-packages (from tf-agents) (1.23.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./venv/lib/python3.9/site-packages (from tf-agents) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-probability>=0.16.0 in ./venv/lib/python3.9/site-packages (from tf-agents) (0.17.0)\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.9/site-packages (from tf-agents) (9.2.0)\n",
      "Requirement already satisfied: protobuf>=3.11.3 in ./venv/lib/python3.9/site-packages (from tf-agents) (3.19.4)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in ./venv/lib/python3.9/site-packages (from gym<=0.23.0,>=0.17.0->tf-agents) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in ./venv/lib/python3.9/site-packages (from gym<=0.23.0,>=0.17.0->tf-agents) (4.12.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in ./venv/lib/python3.9/site-packages (from tensorflow-probability>=0.16.0->tf-agents) (0.4.0)\n",
      "Requirement already satisfied: dm-tree in ./venv/lib/python3.9/site-packages (from tensorflow-probability>=0.16.0->tf-agents) (0.1.7)\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.9/site-packages (from tensorflow-probability>=0.16.0->tf-agents) (5.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.9/site-packages (from importlib-metadata>=4.10.0->gym<=0.23.0,>=0.17.0->tf-agents) (3.8.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyglet in ./venv/lib/python3.9/site-packages (1.5.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imageio\n",
    "%pip install pyvirtualdisplay\n",
    "%pip install tf-agents\n",
    "%pip install pyglet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Seed for PPO actor network\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# PPO Agent\n",
    "from tf_agents.agents.ppo import ppo_agent\n",
    "from tf_agents.agents.ppo import ppo_actor_network\n",
    "from tf_agents.networks import value_network\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.agents.ppo import ppo_clip_agent\n",
    "\n",
    "\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "\n",
    "# old agent\n",
    "from tf_agents.agents.categorical_dqn import categorical_dqn_agent\n",
    "from tf_agents.networks import categorical_q_network\n",
    "\n",
    "\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"Acrobot-v1\" # @param {type:\"string\"}\n",
    "\n",
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "\n",
    "observation_tensor_spec = tensor_spec.from_spec(train_env.observation_spec())\n",
    "action_tensor_spec = tensor_spec.from_spec(train_env.action_spec())\n",
    "time_step_tensor_spec = tensor_spec.from_spec(train_env.time_step_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: BoundedTensorSpec(shape=(6,), dtype=tf.float32, name='observation', minimum=array([ -1.      ,  -1.      ,  -1.      ,  -1.      , -12.566371,\n",
      "       -28.274334], dtype=float32), maximum=array([ 1.      ,  1.      ,  1.      ,  1.      , 12.566371, 28.274334],\n",
      "      dtype=float32))\n",
      "Action: BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(2))\n",
      "TimeStep: TimeStep(\n",
      "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'observation': BoundedTensorSpec(shape=(6,), dtype=tf.float32, name='observation', minimum=array([ -1.      ,  -1.      ,  -1.      ,  -1.      , -12.566371,\n",
      "       -28.274334], dtype=float32), maximum=array([ 1.      ,  1.      ,  1.      ,  1.      , 12.566371, 28.274334],\n",
      "      dtype=float32)),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n"
     ]
    }
   ],
   "source": [
    "print('Observation: {0}'.format(observation_tensor_spec))\n",
    "print('Action: {0}'.format(action_tensor_spec))\n",
    "print('TimeStep: {0}'.format(time_step_tensor_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_fc_layers = (128,64,32,16,8,4,2)\n",
    "# value_fc_layers = (128,64,32,16,8,4,2)\n",
    "actor_fc_layers = (64,64)\n",
    "value_fc_layers = (64,64)\n",
    "\n",
    "actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "        observation_tensor_spec,\n",
    "        action_tensor_spec,\n",
    "        fc_layer_params=actor_fc_layers,\n",
    "        activation_fn=tf.nn.tanh,\n",
    "        kernel_initializer=tf.keras.initializers.Orthogonal(seed=1),\n",
    "        # seed_stream_class=DeterministicSeedStream,\n",
    "        seed_stream_class=tfp.util.SeedStream\n",
    ")\n",
    "\n",
    "value_net = value_network.ValueNetwork(\n",
    "    observation_tensor_spec,\n",
    "    fc_layer_params=value_fc_layers,\n",
    "    kernel_initializer=tf.keras.initializers.Orthogonal()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 22:51:18.252057: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-4 \n",
    "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent_ppo = ppo_agent.PPOAgent(\n",
    "    time_step_spec=time_step_tensor_spec,\n",
    "    action_spec=action_tensor_spec,\n",
    "    actor_net=actor_net,\n",
    "    value_net=value_net,\n",
    "    optimizer=optimizer,\n",
    "    train_step_counter=train_step_counter,\n",
    "    # compute_value_and_advantage_in_train=True,\n",
    "    # update_normalizers_in_train=False,\n",
    "    num_epochs=10\n",
    ")\n",
    "agent_ppo.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-484.4\n",
      "-500.0\n",
      "-500.0\n"
     ]
    }
   ],
   "source": [
    "num_eval_episodes= 10\n",
    "\n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(\n",
    "   time_step_tensor_spec,\n",
    "    action_tensor_spec,\n",
    "    info_spec=time_step_tensor_spec)\n",
    "\n",
    "def evaluate_policy(policy):\n",
    "  for _ in range(1):\n",
    "    avg= compute_avg_return(eval_env, policy, num_eval_episodes)\n",
    "    print(avg)\n",
    "\n",
    "evaluate_policy(random_policy)\n",
    "\n",
    "evaluate_policy(agent_ppo.policy)\n",
    "\n",
    "evaluate_policy(agent_ppo.collect_policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "replay_buffer_size = 10000\n",
    "replay_buffer_batch_size = 1\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    agent_ppo.collect_policy.trajectory_spec,\n",
    "    batch_size=replay_buffer_batch_size,\n",
    "    max_length=replay_buffer_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_step(environment, policy):\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step.action)\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "    replay_buffer.add_batch(traj)\n",
    "    # print(next_time_step.reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_collect_steps = 1000\n",
    "\n",
    "for _ in range(initial_collect_steps):\n",
    "    collect_step(train_env, agent_ppo.collect_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ribeirg/Documents/pessoal/tg/git/learning-tg-agents/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "n_step_update = 1\n",
    "# batch_size = 64\n",
    "\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, sample_batch_size=batch_size,\n",
    "    num_steps=n_step_update + 1).prefetch(batch_size)\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1000: Average Return = -500.000000\n",
      "step = 2000: Average Return = -500.000000\n",
      "step = 3000: Average Return = -500.000000\n",
      "step = 4000: Average Return = -500.000000\n",
      "step = 5000: Average Return = -500.000000\n",
      "step = 6000: Average Return = -500.000000\n",
      "step = 7000: Average Return = -500.000000\n",
      "step = 8000: Average Return = -500.000000\n",
      "step = 9000: Average Return = -500.000000\n",
      "step = 10000: loss = 55.593971252441406\n",
      "step = 10000: Average Return = -500.000000\n",
      "step = 11000: Average Return = -500.000000\n",
      "step = 12000: Average Return = -500.000000\n",
      "step = 13000: Average Return = -500.000000\n",
      "step = 14000: Average Return = -500.000000\n",
      "step = 15000: Average Return = -500.000000\n",
      "step = 16000: Average Return = -500.000000\n",
      "step = 17000: Average Return = -500.000000\n",
      "step = 18000: Average Return = -500.000000\n",
      "step = 19000: Average Return = -500.000000\n",
      "step = 20000: loss = 24.8603515625\n",
      "step = 20000: Average Return = -500.000000\n",
      "step = 21000: Average Return = -500.000000\n",
      "step = 22000: Average Return = -500.000000\n",
      "step = 23000: Average Return = -500.000000\n",
      "step = 24000: Average Return = -500.000000\n",
      "step = 25000: Average Return = -500.000000\n",
      "step = 26000: Average Return = -500.000000\n",
      "step = 27000: Average Return = -500.000000\n",
      "step = 28000: Average Return = -500.000000\n",
      "step = 29000: Average Return = -500.000000\n",
      "step = 30000: loss = 1378.5733642578125\n",
      "step = 30000: Average Return = -500.000000\n",
      "step = 31000: Average Return = -500.000000\n",
      "step = 32000: Average Return = -500.000000\n",
      "step = 33000: Average Return = -500.000000\n",
      "step = 34000: Average Return = -500.000000\n",
      "step = 35000: Average Return = -500.000000\n",
      "step = 36000: Average Return = -500.000000\n",
      "step = 37000: Average Return = -500.000000\n",
      "step = 38000: Average Return = -500.000000\n",
      "step = 39000: Average Return = -500.000000\n",
      "step = 40000: loss = 10.844215393066406\n",
      "step = 40000: Average Return = -500.000000\n",
      "step = 41000: Average Return = -500.000000\n",
      "step = 42000: Average Return = -500.000000\n",
      "step = 43000: Average Return = -500.000000\n",
      "step = 44000: Average Return = -500.000000\n",
      "step = 45000: Average Return = -500.000000\n",
      "step = 46000: Average Return = -500.000000\n",
      "step = 47000: Average Return = -500.000000\n",
      "step = 48000: Average Return = -500.000000\n",
      "step = 49000: Average Return = -500.000000\n",
      "step = 50000: loss = 11.724477767944336\n",
      "step = 50000: Average Return = -500.000000\n",
      "step = 51000: Average Return = -500.000000\n",
      "step = 52000: Average Return = -500.000000\n",
      "step = 53000: Average Return = -500.000000\n",
      "step = 54000: Average Return = -500.000000\n",
      "step = 55000: Average Return = -500.000000\n",
      "step = 56000: Average Return = -500.000000\n",
      "step = 57000: Average Return = -500.000000\n",
      "step = 58000: Average Return = -500.000000\n",
      "step = 59000: Average Return = -500.000000\n",
      "step = 60000: loss = 7.518816947937012\n",
      "step = 60000: Average Return = -500.000000\n",
      "step = 61000: Average Return = -500.000000\n",
      "step = 62000: Average Return = -500.000000\n",
      "step = 63000: Average Return = -500.000000\n",
      "step = 64000: Average Return = -500.000000\n",
      "step = 65000: Average Return = -500.000000\n",
      "step = 66000: Average Return = -500.000000\n",
      "step = 67000: Average Return = -500.000000\n",
      "step = 68000: Average Return = -500.000000\n",
      "step = 69000: Average Return = -500.000000\n",
      "step = 70000: loss = 1254.140380859375\n",
      "step = 70000: Average Return = -500.000000\n",
      "step = 71000: Average Return = -500.000000\n",
      "step = 72000: Average Return = -500.000000\n",
      "step = 73000: Average Return = -500.000000\n",
      "step = 74000: Average Return = -500.000000\n",
      "step = 75000: Average Return = -500.000000\n",
      "step = 76000: Average Return = -500.000000\n",
      "step = 77000: Average Return = -500.000000\n",
      "step = 78000: Average Return = -500.000000\n",
      "step = 79000: Average Return = -500.000000\n",
      "step = 80000: loss = 1271.674560546875\n",
      "step = 80000: Average Return = -500.000000\n",
      "step = 81000: Average Return = -500.000000\n",
      "step = 82000: Average Return = -500.000000\n",
      "step = 83000: Average Return = -500.000000\n",
      "step = 84000: Average Return = -500.000000\n",
      "step = 85000: Average Return = -500.000000\n",
      "step = 86000: Average Return = -500.000000\n",
      "step = 87000: Average Return = -500.000000\n",
      "step = 88000: Average Return = -500.000000\n",
      "step = 89000: Average Return = -500.000000\n",
      "step = 90000: loss = 9.005462646484375\n",
      "step = 90000: Average Return = -500.000000\n",
      "step = 91000: Average Return = -500.000000\n",
      "step = 92000: Average Return = -500.000000\n",
      "step = 93000: Average Return = -500.000000\n",
      "step = 94000: Average Return = -500.000000\n",
      "step = 95000: Average Return = -500.000000\n",
      "step = 96000: Average Return = -500.000000\n",
      "step = 97000: Average Return = -500.000000\n",
      "step = 98000: Average Return = -500.000000\n",
      "step = 99000: Average Return = -500.000000\n",
      "step = 100000: loss = 16.56009292602539\n",
      "step = 100000: Average Return = -500.000000\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 10000\n",
    "num_eval_episodes = 10\n",
    "eval_interval = int(num_iterations/10)\n",
    "log_interval = eval_interval * 10\n",
    "collect_steps_per_iteration = 10\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent_ppo.train = common.function(agent_ppo.train)\n",
    "agent_ppo.train_step_counter.assign(0)\n",
    "\n",
    "avg_return = compute_avg_return(eval_env, agent_ppo.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "returns\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, agent_ppo.collect_policy)\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent_ppo.train(experience).loss\n",
    "\n",
    "  step = agent_ppo.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent_ppo.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1:2f}'.format(step, avg_return))\n",
    "    returns.append(avg_return)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-527.5, 550.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = range(0, num_iterations + 1, 100)\n",
    "# steps = range(0, num_iterations + 1, 10)\n",
    "plt.plot(steps, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim(top=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1417812230.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [26]\u001b[0;36m\u001b[0m\n\u001b[0;31m    train_env._action_spec.\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_env._action_spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bd2ee761d2d7da4166c50099226d582fd9408a55bb0c94aecff2a6acb1ce196"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
